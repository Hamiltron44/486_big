{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/125.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  122.9/125.4 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 125.4/125.4 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "   ---------------------------------------- 0.0/40.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 40.3/40.3 kB ? eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\spenc\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install geopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "   ---------------------------------------- 0.0/167.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 167.3/167.3 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "   ---------------------------------------- 0.0/99.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 99.9/99.9 kB ? eta 0:00:00\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.4/70.4 kB ? eta 0:00:00\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "   ---------------------------------------- 0.0/126.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 126.3/126.3 kB ? eta 0:00:00\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.3.2 idna-3.10 requests-2.32.3 urllib3-2.2.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\Users\\spenc\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Your API key\n",
    "api_key = 'WTCKQMFXBWJSST6TGTZCVZF5Y' #spencerhamilton60@gmail.com\n",
    "api_key = 'HR23S3BURZPNU7DBHQA9GAYZY' #rhamilt4@byu.edu\n",
    "api_key = '3N2JVBHZHRS8SS4WVVA2DN7LW' #fake email 1\n",
    "api_key = 'JAQ9AZB224ATD3UZ9YLR58USU' #fake email 2\n",
    "\n",
    "# Base URL for VisualCrossingWeather API\n",
    "base_url = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/'\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"tester_yeah_with_weather.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Incident Date', 'Park Name', 'Cause of Death',\n",
       "       'Cause of Death Group \\n(Used in the NPS Mortality Dashboard) ',\n",
       "       'Intent', 'Outcome', 'Sex', 'Age Range', 'Activity', 'temperature',\n",
       "       'precipitation', 'humidity', 'date', 'latlong', 'latitude',\n",
       "       'longitude'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row = df.head(1)  # Get the first row as a DataFrame\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Incident Date                             Park Name Cause of Death  \\\n",
      "0      1/1/2007  Glen Canyon National Recreation Area   Undetermined   \n",
      "\n",
      "  Cause of Death Group \\n(Used in the NPS Mortality Dashboard)         Intent  \\\n",
      "0                                       Undetermined             Undetermined   \n",
      "\n",
      "        Outcome   Sex Age Range      Activity  temperature  precipitation  \\\n",
      "0  Fatal injury  Male       65+  Not Reported          NaN            NaN   \n",
      "\n",
      "   humidity        date                                latlong   latitude  \\\n",
      "0       NaN  2007-01-01  ('37.6580958', '-111.09320889669256')  37.658096   \n",
      "\n",
      "    longitude  \n",
      "0 -111.093209  \n"
     ]
    }
   ],
   "source": [
    "#change the date info: \n",
    "# Convert 'date' column from m/d/y to yyyy-MM-dd\n",
    "df['date'] = pd.to_datetime(df['Incident Date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Check the first row to confirm the format\n",
    "print(df.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unique places\n",
    "my_unique = df['Park Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0              Glen Canyon National Recreation Area\n",
      "1              Golden Gate National Recreation Area\n",
      "2              Golden Gate National Recreation Area\n",
      "3                             Natchez Trace Parkway\n",
      "4                             Natchez Trace Parkway\n",
      "                           ...                     \n",
      "4630          Valley Forge National Historical Park\n",
      "4631    Delaware Water Gap National Recreation Area\n",
      "4632                  Point Reyes National Seashore\n",
      "4633                     Grand Canyon National Park\n",
      "4634    Delaware Water Gap National Recreation Area\n",
      "Name: Park Name, Length: 4635, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(my_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find address for National Capital Parks-East\n",
      "Could not find address for Colonial National Historical Park\n",
      "Could not find address for Clara Barton National Historic Site\n",
      "Could not find address for President's Park (White House)\n",
      "Could not find address for Not Reported\n",
      "Could not find address for Yorktown Battlefield Part of Colonial National Historical Park\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'park_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'park_name'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m         latlong_dict[park] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# In case address isn't found\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Step 3: Map the latlong info to the original DataFrame and add a 'latlong' column\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatlong\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpark_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmap(latlong_dict)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# The DataFrame now has a new 'latlong' column with tuples (lat, lon) for each park\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Preview the updated DataFrame\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'park_name'"
     ]
    }
   ],
   "source": [
    "#first I need to get the park names into real addresses:\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_park_address(park_name):\n",
    "    url = f'https://nominatim.openstreetmap.org/search?q={park_name}&format=json&limit=1'\n",
    "    headers = {\n",
    "        'User-Agent': 'sphamiltronics668 (spencerhamilton60@gmailcom)'  # Replace with your app name and contact info\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if data:\n",
    "            park_info = data[0]\n",
    "            return {\n",
    "                'display_name': park_info['display_name'],\n",
    "                'lat': park_info['lat'],\n",
    "                'lon': park_info['lon']\n",
    "            }\n",
    "        else:\n",
    "            print(f\"Could not find address for {park_name}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching address for {park_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Step 1: Extract unique park names from your DataFrame\n",
    "unique_parks = df['Outcome'].unique()  # Replace 'park_name' with the correct column name in your DataFrame\n",
    "\n",
    "# Step 2: Fetch latitude and longitude for each unique park name\n",
    "latlong_dict = {}\n",
    "for park in unique_parks:\n",
    "    address_info = get_park_address(park)  # Use the get_park_address function we defined earlier\n",
    "    if address_info:\n",
    "        latlong_dict[park] = (address_info['lat'], address_info['lon'])\n",
    "    else:\n",
    "        latlong_dict[park] = (None, None)  # In case address isn't found\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latlong_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Map the latlong info to the original DataFrame and add a 'latlong' column\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatlong\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPark Name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(\u001b[43mlatlong_dict\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# The DataFrame now has a new 'latlong' column with tuples (lat, lon) for each park\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())  \u001b[38;5;66;03m# Preview the updated DataFrame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latlong_dict' is not defined"
     ]
    }
   ],
   "source": [
    "# Step 3: Map the latlong info to the original DataFrame and add a 'latlong' column\n",
    "df['latlong'] = df['Park Name'].map(latlong_dict)\n",
    "\n",
    "# The DataFrame now has a new 'latlong' column with tuples (lat, lon) for each park\n",
    "print(df.head())  # Preview the updated DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parks with valid latlongs: 1\n",
      "which is pretty good bc there a total of (1, 16) observations\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Count how many rows have valid latlong values (not equal to (None, None))\n",
    "valid_latlong_count = df[df['latlong'] != (None, None)].shape[0]\n",
    "\n",
    "# Display the result\n",
    "print(f\"Number of parks with valid latlongs: {valid_latlong_count}\")\n",
    "print(f\"which is pretty good bc there a total of {df.shape} observations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as national_parks_with_coordinates.csv\n"
     ]
    }
   ],
   "source": [
    "#save the latlong version\n",
    "# Save the updated DataFrame to a CSV file\n",
    "df.to_csv('national_parks_with_coordinates.csv', index=False)\n",
    "\n",
    "print(\"Dataset saved as national_parks_with_coordinates.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get weather data for a specific location and date\n",
    "def get_weather_data(location, date):\n",
    "    url = f'{base_url}{location}/{date}?key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data.get('currentConditions', {})\n",
    "    else:\n",
    "        print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.6580958,-111.09320889669256\n"
     ]
    }
   ],
   "source": [
    "for i, row in df.head(1).iterrows():  # Removed head(1) to loop through the entire DataFrame\n",
    "    location = f\"{row['latlong'][0]},{row['latlong'][1]}\"\n",
    "    print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             latlong   latitude   longitude\n",
      "0  (37.6580958, -111.09320889669256)  37.658096 -111.093209\n",
      "1         (37.8499275, -122.5177518)  37.849927 -122.517752\n",
      "2         (37.8499275, -122.5177518)  37.849927 -122.517752\n",
      "3          (32.0071549, -90.8585141)  32.007155  -90.858514\n",
      "4          (32.0071549, -90.8585141)  32.007155  -90.858514\n"
     ]
    }
   ],
   "source": [
    "# Function to safely extract latitude and longitude\n",
    "def extract_lat_long(latlong):\n",
    "    if latlong == (None, None):  # Check for (None, None)\n",
    "        return None, None\n",
    "    elif isinstance(latlong, tuple) and len(latlong) == 2:\n",
    "        return float(latlong[0]), float(latlong[1])\n",
    "    else:\n",
    "        return None, None  # Return None for invalid data\n",
    "\n",
    "# Apply the function to create new columns\n",
    "df['latitude'], df['longitude'] = zip(*df['latlong'].apply(extract_lat_long))\n",
    "\n",
    "# Check the updated DataFrame\n",
    "print(df[['latlong', 'latitude', 'longitude']].head())\n",
    "\n",
    "\n",
    "df.to_csv('national_parks_with_float_coors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the one I'm using ___\n",
    "\n",
    "\n",
    "# Loop through your dataset\n",
    "for i, row in df.head(1).iterrows():  # Removed head(1) to loop through the entire DataFrame\n",
    "    # Format the location as a string with six decimal places\n",
    "    location = f\"{row['latitude']:.6f},{row['longitude']:.6f}\"  # Limits to six decimal places\n",
    "\n",
    "    date = row['date']  # Ensure this is in the correct format (yyyy-MM-dd)\n",
    "    \n",
    "    if row['latlong'] == (None, None):  # Check for valid latlong\n",
    "        continue\n",
    "    \n",
    "    # Request weather data\n",
    "    weather_data = get_weather_data(location, date)\n",
    "    \n",
    "    # Append data to the respective columns\n",
    "    if weather_data:\n",
    "        df.at[i, 'temperature'] = weather_data.get('temp', None)\n",
    "        df.at[i, 'precipitation'] = weather_data.get('precip', None)\n",
    "        df.at[i, 'humidity'] = weather_data.get('humidity', None)\n",
    "    \n",
    "    # To avoid hitting the API rate limit, sleep between requests (adjust as needed)\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the updated dataset with weather data\n",
    "df.to_csv('dataset_with_weather.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Incident Date</th>\n",
       "      <th>Park Name</th>\n",
       "      <th>Cause of Death</th>\n",
       "      <th>Cause of Death Group \\n(Used in the NPS Mortality Dashboard)</th>\n",
       "      <th>Intent</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age Range</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2007</td>\n",
       "      <td>Glen Canyon National Recreation Area</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Undetermined</td>\n",
       "      <td>Fatal injury</td>\n",
       "      <td>Male</td>\n",
       "      <td>65+</td>\n",
       "      <td>Not Reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Incident Date                             Park Name Cause of Death  \\\n",
       "0      1/1/2007  Glen Canyon National Recreation Area   Undetermined   \n",
       "\n",
       "  Cause of Death Group \\n(Used in the NPS Mortality Dashboard)         Intent  \\\n",
       "0                                       Undetermined             Undetermined   \n",
       "\n",
       "        Outcome   Sex Age Range      Activity  \n",
       "0  Fatal injury  Male       65+  Not Reported  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fatal injury' 'Fatal Injury']\n"
     ]
    }
   ],
   "source": [
    "unique_parks = df['Outcome'].unique() \n",
    "print(unique_parks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tester_guy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Example usage in your loop\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtester_guy\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     30\u001b[0m     latitude \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     31\u001b[0m     longitude \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tester_guy' is not defined"
     ]
    }
   ],
   "source": [
    "# new Real??\n",
    "def get_weather_data(location, date):\n",
    "    url = f'{base_url}{location}/{date}?key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Extract the relevant data\n",
    "        data = response.json()\n",
    "        \n",
    "        # Here we assume that data contains hourly weather info, adapt based on actual structure\n",
    "        hourly_data = data.get('hours', [])\n",
    "        filtered_data = []\n",
    "        \n",
    "        for hour in hourly_data:\n",
    "            filtered_data.append({\n",
    "                'datetime': hour.get('datetime'),\n",
    "                'temp': hour.get('temp'),\n",
    "                'humidity': hour.get('humidity'),\n",
    "                'precip': hour.get('precip'),\n",
    "                'conditions': hour.get('conditions'),\n",
    "            })\n",
    "        \n",
    "        return filtered_data\n",
    "    else:\n",
    "        print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Example usage in your loop\n",
    "for i, row in tester_guy.iterrows():\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    date = row['date']\n",
    "\n",
    "    if (latitude is None) or (longitude is None):\n",
    "        continue\n",
    "\n",
    "    # Format location\n",
    "    location = f\"{latitude:.6f},{longitude:.6f}\"\n",
    "    \n",
    "    # Request weather data\n",
    "    weather_data = get_weather_data(location, date)\n",
    "\n",
    "    # Append filtered data to the DataFrame\n",
    "    for hour_data in weather_data:\n",
    "        df.at[i, 'datetime'] = hour_data['datetime']\n",
    "        df.at[i, 'temperature'] = hour_data['temp']\n",
    "        df.at[i, 'humidity'] = hour_data['humidity']\n",
    "        df.at[i, 'precipitation'] = hour_data['precip']\n",
    "        df.at[i, 'conditions'] = hour_data['conditions']\n",
    "    \n",
    "    # Sleep to avoid hitting the API rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the updated dataset with relevant weather data\n",
    "tester_guy.to_csv('tester_yeah_with_weather.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'queryCost': 24, 'latitude': 37.7213, 'longitude': -119.626, 'resolvedAddress': '37.7213,-119.626', 'address': '37.7213,-119.626', 'timezone': 'America/Los_Angeles', 'tzoffset': -7.0, 'days': [{'datetime': '2021-07-15', 'datetimeEpoch': 1626332400, 'tempmax': 87.6, 'tempmin': 56.5, 'temp': 71.6, 'feelslikemax': 84.0, 'feelslikemin': 56.5, 'feelslike': 70.6, 'dew': 29.0, 'humidity': 24.4, 'precip': 0.0, 'precipprob': 0.0, 'precipcover': 0.0, 'preciptype': None, 'snow': 0.0, 'snowdepth': 0.0, 'windgust': 28.6, 'windspeed': 7.6, 'winddir': 216.4, 'pressure': 1014.4, 'cloudcover': 0.3, 'visibility': 9.6, 'solarradiation': 370.5, 'solarenergy': 32.1, 'uvindex': 10.0, 'sunrise': '05:49:06', 'sunriseEpoch': 1626353346, 'sunset': '20:19:41', 'sunsetEpoch': 1626405581, 'moonphase': 0.2, 'conditions': 'Clear', 'description': 'Clear conditions throughout the day.', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', '72061500206', 'CQ160', 'EPWC1', 'KMMH'], 'source': 'obs', 'hours': [{'datetime': '00:00:00', 'datetimeEpoch': 1626332400, 'temp': 62.8, 'feelslike': 62.8, 'humidity': 32.42, 'dew': 32.8, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 15.0, 'windspeed': 3.7, 'winddir': 322.0, 'pressure': 1018.6, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'KMMH'], 'source': 'obs'}, {'datetime': '01:00:00', 'datetimeEpoch': 1626336000, 'temp': 62.3, 'feelslike': 62.3, 'humidity': 35.58, 'dew': 34.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.2, 'windspeed': 3.4, 'winddir': 330.0, 'pressure': 1015.7, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', '72061500206'], 'source': 'obs'}, {'datetime': '02:00:00', 'datetimeEpoch': 1626339600, 'temp': 59.9, 'feelslike': 59.9, 'humidity': 38.66, 'dew': 34.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.2, 'windspeed': 4.0, 'winddir': 94.0, 'pressure': 1015.8, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', 'KBAN', '72061500206', 'KMMH'], 'source': 'obs'}, {'datetime': '03:00:00', 'datetimeEpoch': 1626343200, 'temp': 59.6, 'feelslike': 59.6, 'humidity': 36.8, 'dew': 33.1, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.2, 'windspeed': 2.9, 'winddir': 0.0, 'pressure': 1012.1, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', 'KBAN', '72061500206'], 'source': 'obs'}, {'datetime': '04:00:00', 'datetimeEpoch': 1626346800, 'temp': 56.9, 'feelslike': 56.9, 'humidity': 42.15, 'dew': 34.1, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.2, 'windspeed': 3.4, 'winddir': 353.0, 'pressure': 1015.7, 'visibility': 9.9, 'cloudcover': 1.3, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', 'KBAN', '72061500206', 'KMMH'], 'source': 'obs'}, {'datetime': '05:00:00', 'datetimeEpoch': 1626350400, 'temp': 56.9, 'feelslike': 56.9, 'humidity': 42.28, 'dew': 34.2, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.0, 'windspeed': 3.3, 'winddir': 78.1, 'pressure': 1015.8, 'visibility': 9.9, 'cloudcover': 2.1, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', 'KBAN', '72061500206', 'KMMH'], 'source': 'obs'}, {'datetime': '06:00:00', 'datetimeEpoch': 1626354000, 'temp': 56.5, 'feelslike': 56.5, 'humidity': 44.07, 'dew': 34.9, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.0, 'windspeed': 3.2, 'winddir': 78.3, 'pressure': 1013.2, 'visibility': 9.1, 'cloudcover': 0.0, 'solarradiation': 1.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '07:00:00', 'datetimeEpoch': 1626357600, 'temp': 58.3, 'feelslike': 58.3, 'humidity': 47.7, 'dew': 38.5, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 13.2, 'windspeed': 2.8, 'winddir': 60.0, 'pressure': 1017.2, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 75.0, 'solarenergy': 0.3, 'uvindex': 1.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '08:00:00', 'datetimeEpoch': 1626361200, 'temp': 64.6, 'feelslike': 64.6, 'humidity': 36.74, 'dew': 37.6, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 14.8, 'windspeed': 2.7, 'winddir': 94.0, 'pressure': 1019.4, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 286.0, 'solarenergy': 1.0, 'uvindex': 3.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'CQ160', 'KMMH'], 'source': 'obs'}, {'datetime': '09:00:00', 'datetimeEpoch': 1626364800, 'temp': 75.7, 'feelslike': 75.7, 'humidity': 20.35, 'dew': 32.2, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 21.9, 'windspeed': 4.3, 'winddir': 177.0, 'pressure': 1015.9, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 494.0, 'solarenergy': 1.8, 'uvindex': 5.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206', 'KMMH'], 'source': 'obs'}, {'datetime': '10:00:00', 'datetimeEpoch': 1626368400, 'temp': 79.6, 'feelslike': 79.6, 'humidity': 15.41, 'dew': 28.6, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 19.7, 'windspeed': 4.7, 'winddir': 178.0, 'pressure': 1015.5, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 689.0, 'solarenergy': 2.5, 'uvindex': 7.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206', 'KMMH'], 'source': 'obs'}, {'datetime': '11:00:00', 'datetimeEpoch': 1626372000, 'temp': 82.4, 'feelslike': 79.9, 'humidity': 10.55, 'dew': 21.6, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 28.6, 'windspeed': 6.4, 'winddir': 236.0, 'pressure': 1015.4, 'visibility': 9.0, 'cloudcover': 0.0, 'solarradiation': 785.0, 'solarenergy': 2.8, 'uvindex': 8.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'EPWC1', '72061500206'], 'source': 'obs'}, {'datetime': '12:00:00', 'datetimeEpoch': 1626375600, 'temp': 85.0, 'feelslike': 81.9, 'humidity': 8.09, 'dew': 17.4, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 20.8, 'windspeed': 5.3, 'winddir': 220.0, 'pressure': 1011.9, 'visibility': 9.1, 'cloudcover': 0.0, 'solarradiation': 964.0, 'solarenergy': 3.5, 'uvindex': 10.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '13:00:00', 'datetimeEpoch': 1626379200, 'temp': 85.6, 'feelslike': 82.4, 'humidity': 10.48, 'dew': 24.0, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 21.9, 'windspeed': 7.0, 'winddir': 203.0, 'pressure': 1015.0, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 1021.0, 'solarenergy': 3.7, 'uvindex': 10.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '14:00:00', 'datetimeEpoch': 1626382800, 'temp': 87.0, 'feelslike': 83.4, 'humidity': 10.5, 'dew': 25.0, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 24.2, 'windspeed': 7.6, 'winddir': 222.0, 'pressure': 1014.9, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 1023.0, 'solarenergy': 3.7, 'uvindex': 10.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '15:00:00', 'datetimeEpoch': 1626386400, 'temp': 87.6, 'feelslike': 84.0, 'humidity': 8.36, 'dew': 20.1, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 24.2, 'windspeed': 7.2, 'winddir': 240.0, 'pressure': 1011.1, 'visibility': 9.1, 'cloudcover': 0.0, 'solarradiation': 970.0, 'solarenergy': 3.5, 'uvindex': 10.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'EPWC1', '72061500206'], 'source': 'obs'}, {'datetime': '16:00:00', 'datetimeEpoch': 1626390000, 'temp': 86.8, 'feelslike': 83.3, 'humidity': 9.78, 'dew': 23.2, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 24.2, 'windspeed': 7.1, 'winddir': 220.0, 'pressure': 1011.1, 'visibility': 7.8, 'cloudcover': 0.0, 'solarradiation': 873.0, 'solarenergy': 3.1, 'uvindex': 9.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'EPWC1', '72061500206'], 'source': 'obs'}, {'datetime': '17:00:00', 'datetimeEpoch': 1626393600, 'temp': 85.0, 'feelslike': 81.9, 'humidity': 9.33, 'dew': 20.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 24.2, 'windspeed': 6.6, 'winddir': 219.0, 'pressure': 1010.8, 'visibility': 9.1, 'cloudcover': 0.0, 'solarradiation': 717.0, 'solarenergy': 2.6, 'uvindex': 7.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '18:00:00', 'datetimeEpoch': 1626397200, 'temp': 83.0, 'feelslike': 80.3, 'humidity': 11.44, 'dew': 24.0, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 20.8, 'windspeed': 5.5, 'winddir': 220.0, 'pressure': 1011.0, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 533.0, 'solarenergy': 1.9, 'uvindex': 5.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '19:00:00', 'datetimeEpoch': 1626400800, 'temp': 77.1, 'feelslike': 77.1, 'humidity': 14.56, 'dew': 25.2, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 21.8, 'windspeed': 6.2, 'winddir': 258.0, 'pressure': 1017.1, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 329.0, 'solarenergy': 1.2, 'uvindex': 3.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', 'CQ160', 'KMMH'], 'source': 'obs'}, {'datetime': '20:00:00', 'datetimeEpoch': 1626404400, 'temp': 73.4, 'feelslike': 73.4, 'humidity': 22.24, 'dew': 32.5, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 17.4, 'windspeed': 3.3, 'winddir': 230.0, 'pressure': 1011.5, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 128.0, 'solarenergy': 0.5, 'uvindex': 1.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '21:00:00', 'datetimeEpoch': 1626408000, 'temp': 68.2, 'feelslike': 68.2, 'humidity': 22.07, 'dew': 27.9, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 9.8, 'windspeed': 1.7, 'winddir': 188.9, 'pressure': 1011.4, 'visibility': 9.9, 'cloudcover': 0.0, 'solarradiation': 4.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}, {'datetime': '22:00:00', 'datetimeEpoch': 1626411600, 'temp': 64.4, 'feelslike': 64.4, 'humidity': 27.02, 'dew': 29.7, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 9.2, 'windspeed': 2.6, 'winddir': 190.0, 'pressure': 1015.1, 'visibility': 9.9, 'cloudcover': 2.8, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', 'KBAN', '72061500206', 'KMMH'], 'source': 'obs'}, {'datetime': '23:00:00', 'datetimeEpoch': 1626415200, 'temp': 61.0, 'feelslike': 61.0, 'humidity': 29.71, 'dew': 29.1, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 10.3, 'windspeed': 2.6, 'winddir': 110.0, 'pressure': 1015.4, 'visibility': 9.0, 'cloudcover': 0.0, 'solarradiation': 0.0, 'solarenergy': 0.0, 'uvindex': 0.0, 'conditions': 'Clear', 'icon': 'clear-night', 'stations': ['72065200433', '99999953150', '72389403181', 'KBAN', '72061500206'], 'source': 'obs'}]}], 'stations': {'72065200433': {'distance': 71241.0, 'latitude': 38.356, 'longitude': -119.519, 'useCount': 0, 'id': '72065200433', 'name': 'BRIDGEPORT SONORA JUNCTION, CA US', 'quality': 99, 'contribution': 0.0}, '99999953150': {'distance': 17677.0, 'latitude': 37.759, 'longitude': -119.821, 'useCount': 0, 'id': '99999953150', 'name': 'YOSEMITE VILLAGE 12 W, CA US', 'quality': 100, 'contribution': 0.0}, '72389403181': {'distance': 69068.0, 'latitude': 37.633, 'longitude': -118.85, 'useCount': 0, 'id': '72389403181', 'name': 'MAMMOTH LAKES MAMMOTH YOSEMITE AIRPORT, CA US', 'quality': 69, 'contribution': 0.0}, 'KBAN': {'distance': 70722.0, 'latitude': 38.35, 'longitude': -119.51, 'useCount': 0, 'id': 'KBAN', 'name': 'KBAN', 'quality': 99, 'contribution': 0.0}, '72061500206': {'distance': 77683.0, 'latitude': 38.033, 'longitude': -120.417, 'useCount': 0, 'id': '72061500206', 'name': 'COLUMBIA AIRPORT, CA US', 'quality': 49, 'contribution': 0.0}, 'CQ160': {'distance': 7130.0, 'latitude': 37.711, 'longitude': -119.706, 'useCount': 0, 'id': 'CQ160', 'name': 'Yosemite NP-Turtleback Dome CA US CARB', 'quality': 0, 'contribution': 0.0}, 'EPWC1': {'distance': 15160.0, 'latitude': 37.675, 'longitude': -119.788, 'useCount': 0, 'id': 'EPWC1', 'name': 'EL PORTAL CA US', 'quality': 0, 'contribution': 0.0}, 'KMMH': {'distance': 71229.0, 'latitude': 37.61, 'longitude': -118.83, 'useCount': 0, 'id': 'KMMH', 'name': 'KMMH', 'quality': 91, 'contribution': 0.0}}}\n"
     ]
    }
   ],
   "source": [
    "test_park = \"Yosemite National Park\"\n",
    "test_date = \"2021-07-15\"\n",
    "\n",
    "url = f'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/37.7213,-119.626/{test_date}?key={api_key}'\n",
    "response = requests.get(url)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datetime': '12:00:00', 'datetimeEpoch': 1626375600, 'temp': 85.0, 'feelslike': 81.9, 'humidity': 8.09, 'dew': 17.4, 'precip': 0.0, 'precipprob': 0.0, 'snow': 0.0, 'snowdepth': 0.0, 'preciptype': None, 'windgust': 20.8, 'windspeed': 5.3, 'winddir': 220.0, 'pressure': 1011.9, 'visibility': 9.1, 'cloudcover': 0.0, 'solarradiation': 964.0, 'solarenergy': 3.5, 'uvindex': 10.0, 'conditions': 'Clear', 'icon': 'clear-day', 'stations': ['72065200433', '99999953150', 'KBAN', 'CQ160', '72061500206'], 'source': 'obs'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "test_park = \"Yosemite National Park\"\n",
    "test_date = \"2021-07-15\"\n",
    "api_key = 'HR23S3BURZPNU7DBHQA9GAYZY' #rhamilt4@byu.edu\n",
    "\n",
    "url = f'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/37.7213,-119.626/{test_date}?key={api_key}&include=hours'\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # Filter to get only the 12 p.m. data\n",
    "    noon_data = next((hour for hour in data['days'][0]['hours'] if hour['datetime'] == '12:00:00'), None)\n",
    "    print(noon_data)\n",
    "else:\n",
    "    print(\"Failed to retrieve data:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = get_weather_data(\"37.7213,-119.626\", \"2021-06-15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Define the base URL for the VisualCrossingWeather API\n",
    "base_url = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/'\n",
    "\n",
    "# Function to get full daily weather data\n",
    "def get_weather_data(location, date, api_key):\n",
    "    # Update the URL to include the 'include' parameter to fetch only daily data\n",
    "    url = f'{base_url}{location}/{date}?key={api_key}&include=days'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return data['days'][0]  # This now includes only the daily data\n",
    "    elif response.status_code in [403, 429]:  # Common codes for invalid key or rate limit\n",
    "        print(f\"API key issue or rate limit reached: {response.status_code}\")\n",
    "        return \"STOP\"\n",
    "    else:\n",
    "        print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Add a new column to store the raw JSON weather data\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"weather__ed.csv\")\n",
    "#df['Weather'] = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Incident Date                             Park Name Cause of Death  \\\n",
      "0      1/1/2007  Glen Canyon National Recreation Area   Undetermined   \n",
      "\n",
      "  Cause of Death Group \\r\\n(Used in the NPS Mortality Dashboard)   \\\n",
      "0                                       Undetermined                \n",
      "\n",
      "         Intent       Outcome   Sex Age Range      Activity  temperature  \\\n",
      "0  Undetermined  Fatal injury  Male       65+  Not Reported          NaN   \n",
      "\n",
      "   precipitation  humidity        date                                latlong  \\\n",
      "0            NaN       NaN  2007-01-01  ('37.6580958', '-111.09320889669256')   \n",
      "\n",
      "    latitude   longitude                                            Weather  \n",
      "0  37.658096 -111.093209  {'datetime': '2007-01-01', 'datetimeEpoch': 11...  \n"
     ]
    }
   ],
   "source": [
    "dfs = df.head(1)\n",
    "api_key = 'HR23S3BURZPNU7DBHQA9GAYZY' #rhamilt4@byu.edu\n",
    "\n",
    "print(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your API key\n",
    "api_key = 'WTCKQMFXBWJSST6TGTZCVZF5Y' #spencerhamilton60@gmail.com\n",
    "api_key = 'HR23S3BURZPNU7DBHQA9GAYZY' #rhamilt4@byu.edu\n",
    "api_key = '3N2JVBHZHRS8SS4WVVA2DN7LW' #fake email 1\n",
    "api_key = 'JAQ9AZB224ATD3UZ9YLR58USU' #fake email 2\n",
    "\n",
    "\n",
    "\n",
    "# Display rows with existing weather data\n",
    "existing_weather_data = df[df['Weather'].notna()]\n",
    "\n",
    "# View the first few rows to inspect the structure and contents\n",
    "#print(existing_weather_data.head())\n",
    "\n",
    "\n",
    "existing_weather_data_length = df['Weather'].notna().sum()\n",
    "#print(existing_weather_data_length)\n",
    "# Save the updated dataset with relevant weather data\n",
    "existing_weather_data.to_csv('weather__ed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming you have defined your base_url and api_key previously\n",
    "base_url = 'https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline/'\n",
    "api_key = api_key = '3N2JVBHZHRS8SS4WVVA2DN7LW' #fake email 1\n",
    "\n",
    "def get_weather_data(location, date):\n",
    "    url = f'{base_url}{location}/{date}?key={api_key}&contentType=csv'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Extract the relevant data\n",
    "        data = response.json()\n",
    "        \n",
    "        # Store the full weather data as a JSON string\n",
    "        return data  # Return all data for now\n",
    "    else:\n",
    "        print(f\"Error fetching data for {location} on {date}: {response.status_code}\")\n",
    "        return False  # Return None on error\n",
    "\n",
    "# Loop through your DataFrame and fetch weather data\n",
    "for i, row in df.iterrows():\n",
    "    # Skip rows that already have weather data\n",
    "    if pd.notna(row['Weather']):\n",
    "        continue\n",
    "\n",
    "    latitude = row['latitude']\n",
    "    longitude = row['longitude']\n",
    "    date = row['date']\n",
    "\n",
    "    if (latitude is None) or (longitude is None):\n",
    "        continue\n",
    "\n",
    "    # Format location\n",
    "    location = f\"{latitude:.6f},{longitude:.6f}\"\n",
    "    \n",
    "    # Request weather data\n",
    "    weather_data = get_weather_data(location, date)\n",
    "    \n",
    "        \n",
    "\n",
    "    if weather_data is not None:\n",
    "        # Store the full JSON response in the 'Weather' column\n",
    "        df.at[i, 'Weather'] = str(weather_data)  # Convert dict to string for storage\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        print(\"stopped bc it was bad\")\n",
    "    \n",
    "    # Sleep to avoid hitting the API rate limit\n",
    "    time.sleep(1)\n",
    "\n",
    "# Save the updated dataset with relevant weather data\n",
    "#df.to_csv('tester_yeah_with_weather.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
